{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744a3042",
   "metadata": {},
   "source": [
    "# Unet Rust detection\n",
    "\n",
    "Authors: Kevin, Gabriel, Charles\n",
    "\n",
    "Description: This code is created for pre processing the masks and the data related to Rust detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b66fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Importing section\n",
    "from tensorflow.keras import models\n",
    "from keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "import numpy as np # IMPORTANT for the task 1\n",
    "from keras import backend as K\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "# Paper Correction\n",
    "from keras import metrics\n",
    "# End importing section\n",
    "import cv2 # IMPORTANT for the task 1\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.io import wavfile\n",
    "import pylab\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "datagen = ImageDataGenerator(rescale=1)\n",
    "batch_size = 32\n",
    "from keras.layers import LeakyReLU, Conv2D, Input, BatchNormalization, Activation, Dense, Dropout, Conv2DTranspose, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7c8f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from cityscapesscripts.helpers.labels import trainId2label as t2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548700e",
   "metadata": {},
   "source": [
    "# Functions used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d53dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_labels_features(directory, sample_count, new_image_shape = (512, 512)):\n",
    "    '''Loads and crop the images according the appropriate conditions. Also, it returns the feature and labels of the VGG16 predictions'''\n",
    "        \n",
    "    images = np.zeros(shape=(sample_count, new_image_shape[0], new_image_shape[1], 3))    \n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                            target_size = new_image_shape,\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary',\n",
    "                                            shuffle = True,\n",
    "                                            seed=0)\n",
    "    i = 0\n",
    "\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "                            \n",
    "        images[i * batch_size : (i + 1) * batch_size] = inputs_batch        \n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "\n",
    "        if i * batch_size >= sample_count:\n",
    "\n",
    "             break\n",
    "    return(images, labels)\n",
    "\n",
    "def get_train_test_data(base_dir = 'input_data/RustData',\n",
    "                        train_sample_size = 45, test_sample_size = 45,  \n",
    "                        new_image_shape = (512, 512), \n",
    "                        rescale = 1):\n",
    "    '''This function imports the dataset and split into train and test data return the features and labels of the images'''\n",
    "        \n",
    "    \n",
    "    # Importing images data\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "    datagen = ImageDataGenerator(rescale=rescale)\n",
    "    batch_size = 20    \n",
    "\n",
    "    # Getting data features and labels    \n",
    "    train_information = get_images_labels_features(directory = train_dir, \n",
    "                                                   sample_count = train_sample_size, \n",
    "                                                   new_image_shape = new_image_shape)    \n",
    "    train_images = train_information[0]\n",
    "    train_labels = train_information[1]\n",
    "    \n",
    "    test_information = get_images_labels_features(directory = test_dir, \n",
    "                                                  sample_count = test_sample_size, \n",
    "                                                  new_image_shape = new_image_shape)    \n",
    "    test_images = test_information[0]\n",
    "    test_labels = test_information[1]\n",
    "\n",
    "    # Preparing data features    \n",
    "    train_labels = to_categorical(train_labels)\n",
    "    test_labels = to_categorical(test_labels)        \n",
    "        \n",
    "    return(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7a33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_labels_features(directory, sample_count, new_image_shape = (512, 512)):\n",
    "    '''Loads and crop the images according the appropriate conditions. Also, it returns the feature and labels of the VGG16 predictions'''\n",
    "        \n",
    "    images = np.zeros(shape=(sample_count, new_image_shape[0], new_image_shape[1], 3))    \n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                            target_size = new_image_shape,\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary',\n",
    "                                            shuffle = True,\n",
    "                                            seed=0)\n",
    "    i = 0\n",
    "\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "                            \n",
    "        images[i * batch_size : (i + 1) * batch_size] = inputs_batch        \n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "\n",
    "        if i * batch_size >= sample_count:\n",
    "\n",
    "             break\n",
    "    return(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49201ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(6, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5ebe1a",
   "metadata": {},
   "source": [
    "# Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = get_train_test_data(base_dir = 'input_data/RustData/',\n",
    "                                                                           train_sample_size = 45, test_sample_size = 45, \n",
    "                                                                           new_image_shape = (512, 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_maks, train_labels_maks, test_images_maks, test_labels_maks = get_train_test_data(base_dir = 'input_data/RustDataMasks/',\n",
    "                                                                               train_sample_size = 45, test_sample_size = 45, \n",
    "                                                                               new_image_shape = (512, 512))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14382f45",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f942854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img (InputLayer)               [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 512, 512, 16  448         ['img[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 512, 512, 16  64         ['conv2d_20[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 512, 512, 16  0           ['batch_normalization_19[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 256, 256, 16  0          ['activation_19[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 256, 256, 16  0           ['max_pooling2d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 256, 256, 32  4640        ['dropout_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 256, 256, 32  128        ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_21[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 32  0          ['activation_21[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128, 128, 32  0           ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 128, 128, 64  18496       ['dropout_9[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 128, 128, 64  256        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 64, 64, 64)   0           ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 64, 64, 128)  73856       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 64, 128)  512        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 128)  0          ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 32, 32, 128)  0           ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 32, 32, 256)  295168      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 128)  295040     ['activation_27[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 64, 64, 256)  0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 64, 64, 128)  295040      ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 64, 64, 128)  512        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 128, 128, 64  73792      ['activation_29[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_5[0][0]',     \n",
      "                                8)                                'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 128, 128, 12  0           ['concatenate_5[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 128, 128, 64  73792       ['dropout_13[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 128, 128, 64  256        ['conv2d_32[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_31[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 256, 256, 32  18464      ['activation_31[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256, 256, 64  0           ['conv2d_transpose_6[0][0]',     \n",
      "                                )                                 'activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 256, 256, 64  0           ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 256, 256, 32  18464       ['dropout_14[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 256, 256, 32  128        ['conv2d_34[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 256, 256, 32  0           ['batch_normalization_33[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 512, 512, 16  4624       ['activation_33[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 512, 512, 32  0           ['conv2d_transpose_7[0][0]',     \n",
      "                                )                                 'activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 512, 512, 32  0           ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 512, 512, 16  4624        ['dropout_15[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 512, 512, 16  64         ['conv2d_36[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 512, 512, 16  0           ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 512, 512, 6)  102         ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,179,494\n",
      "Trainable params: 1,178,022\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((512, 512, 3), name='img')\n",
    "my_model = get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891189b9",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d1766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [    \n",
    "    ModelCheckpoint('model-unet-rust.h5',verbose = 1, save_best_only = True, \n",
    "                    save_weights_only = True, monitor='val_acc')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df186d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer=Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                 metrics=[\"acc\"])\n",
    "results = my_model.fit(train_images, train_images_maks[:, :, :, 0:1], \n",
    "                    batch_size=32, epochs=30, callbacks=callbacks,\n",
    "                    validation_data=(test_images[:, :, :, :], test_images_maks[:, :, :, 0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_performance = pd.DataFrame(results.history)\n",
    "#exploratory_performance.to_csv(\"../../output_data/unet_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_performance.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
